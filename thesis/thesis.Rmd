---
title: Nebula 
subtitle: Comparing two waves of cloud computing 
author: Marius Nilsen Kluften  
documentclass: report
date: 2024
output: 
  pdf_document:
    latex_engine: xelatex
header-includes: 
  - \AtBeginDocument{\let\maketitle\relax}
  - \usepackage{fancyhdr}
  - \usepackage{lastpage}
  - \usepackage{geometry}
  - \usepackage{tocbibind}
  - \usepackage{graphicx}
  - \usepackage{setspace}
  - \usepackage{lipsum}
  - \onehalfspacing
  - \pagestyle{fancy}

  # - \usepackage{tocloft}
  # - \renewcommand\cftchapaftersnum{.}
  # - \renewcommand\cftsecaftersnum{.}
  #
  - \renewcommand\thepart{\Roman{part}}
  # - \renewcommand\thesection{\arabic{section}}
  # - \renewcommand\thesubsection{(\alph{subsection})}

  - \fancyhf{}
  - \renewcommand{\headrulewidth}{0pt}
  - \fancyfoot[C]{}

  - \usepackage{epigraph}
  - \setlength\epigraphwidth{.6\textwidth}

  - \usepackage[fontsize=12pt]{scrextend}
  - \usepackage{fontspec}
  - \setmainfont{Georgia}
  - \usepackage{titlesec}
  - \newfontfamily\headingfont{Avenir}
  - \titleformat*{\section}{\LARGE\headingfont}
  - \titleformat*{\subsection}{\Large\headingfont}
  - \titleformat*{\subsubsection}{\large\headingfont}

---



<!-- -------------------- -->
<!--      COVER PAGE      -->
<!-- -------------------- -->


\begin{titlepage}
\thispagestyle{fancy}
\fancyfoot[C]{2024}
\centering
{\Huge\bfseries Nebula\par}

\vspace{0.5cm}

{\Huge\itshape Comparing two waves of cloud compute\par}

\vspace{1cm}

{\Large Marius Nilsen Kluften\par}

\vspace{1cm}

\includegraphics[width=0.4\textwidth]{../assets/uio-logo.png}\\[1cm]

{\Large Thesis submitted for the degree of\par}
{\Large Master in Informatics: Programming and System Architecture\par}

\vspace{0.25cm}

{\Large 60 credits\par}

\vspace{1cm}

{\Large Institute of Informatics\par}

{\Large Faculty of mathematics and natural sciences\par}

{\Large University of Oslo\par}

\end{titlepage}


<!-- -------------------- -->
<!--      TITLE PAGE      -->
<!-- -------------------- -->

\newpage

\begin{center}
\vspace*{\fill} 
\Huge \textbf{Nebula} \\[10pt]
\vspace{2cm} 
\Large \textit{Comparing two waves of cloud compute} \\[20pt]
\vspace{2cm} 
\Large Marius Nilsen Kluften \\[30pt]
\vspace*{\fill} 
\end{center}


<!-- -------------------- -->
<!--    COPYRIGHT PAGE    -->
<!-- -------------------- -->

\newpage


\null\vfill
\begin{flushleft}
\Large © 2024 Marius Nilsen Kluften\par
\Large Nebula \par
\Large https://duo.uio.no/ \par
\Large Printed: Reprosentralen, University of Oslo \par
\end{flushleft}

\newpage
\fancyfoot[C]{ \thepage\ }
\pagenumbering{roman}

\vspace*{\fill}
\begin{center}
\begin{minipage}{0.75\textwidth}

\section{Abstract}

The ever increasing demand for cloud services has resulted in the expansion of
energy-intensive data centers, the ICT industry accounts for about 1 \% of global 
electricity use, highlighting a need for sustainable options
in cloud computing architectures. 

\vspace{0.25cm}

This project investigates WebAssembly, a technology originally intended for running 
in the browser, as a potential contender in the space of technologies to
consider in cloud native applications. Leveraging the inherent efficiency,
portability and lower startup times of WebAssembly modules, this thesis presents an
approach that aligns with green energy principles, while maintaining performance and
scalability, essential for cloud services. 

\vspace{0.25cm}

Preliminary findings suggest that programs compiled to WebAssembly modules have 
reduced startup and runtimes, which hopefully leads to less energy
consumption and offering a viable pathway towards a more sustainable cloud.

\end{minipage}
\end{center}
\vspace*{\fill}

\newpage

\vspace*{\fill}
\begin{center}
\begin{minipage}{0.75\textwidth}
\section{Acknowledgments}


The idea for the topic for this thesis appeared in an episode of the podcast
"Rustacean station". Matt Butcher, the CEO of Fermyon, told the story of his
journey through the different waves of cloud computing, and why Fermyon 
decided to bet on WebAssembly for the next big wave of cloud compute.

\vspace{0.25cm}

The capabilities of WebAssembly running on the server, with the aid of
the WebAssembly System Interface (WASI) project, caught my interest and started 
the snowball that ended up as the avalanche that is this thesis. 

\vspace{0.25cm}

I'd like to thank Matt Butcher and the people over at Fermyon for inadvertently 
inspiring my topic. 

Furthermore I'd like to thank my two supervisors Joachim T. Kristensen and 
Marcus Kirkedal Thomsen, whom I somehow managed to convinced to help guide me 
through such a cutting edge topic Their guidance and insight have been
invaluable the past semesters.

\end{minipage}
\end{center}
\vspace*{\fill}

\newpage

\epigraph{\itshape 
  If WASM+WASI existed in 2008, we wouldn't have needed to created Docker. 
  That's how important it is. Webassembly on the server is the future of computing.
  A standardized system interface was the missing link. 
  Let's hope WASI is up to the task!
}{---Solomon Hykes, \textit{Founder of Docker}}

\newgeometry{left=3cm, right=3cm, top=3cm, bottom=3cm} 

\newpage


\tableofcontents

\newpage

\listoffigures

\newpage

\listoftables

\newpage

\pagenumbering{arabic}
\fancyfoot[C]{Page \thepage\ of \pageref{LastPage}}

\part{Overview}


\chapter{Introduction}

In the digital age, cloud computing has emerged as a foundational technology in
the technological landscape, driving innovation and increased efficiency across
various sectors. Its growth over the past decade has not only transformed how
consumers store, process, and access data, but also raised environmental
concerns. 

The Information and Communication Technology (ICT) industry, with cloud
computing at its core, is estimated to contribute between 2.1\% to 3.9\% of
global greenhouse gas emissions. Data centers, which are crucial to cloud
computing infrastructures, account for about 200 TWh/yr, or about 1\% of the
global electricity consumption. [(Freitag et al., 2021)][1]. This consumption is
projected to increase dramatically increase, potentially accounting for  15\% to
30\% of electricity consumption in some countries by 2030. 

In Norway, for example, Google is in the process of constructing a data center
in Skien, expected to be fully operational by 2026. This facility alone is
estimated to require 7.5TWh/yr, amounting to 25% of Google's total power
consumption world wide.(TODO: SRC) Google has commited to powering this data
center entirely with renewable energy, aiming for a net-zero carbon footprint.
However, this commitment is not universally adopted, and many data centers still
rely on electricity generated by fossil fuels, a leading contributor to climate
change [(Mytton, D. 2021)][2]

It is important to note is that these measurements and estimates comes with a
certain level of uncertainty, yet they offer a glimpse into the current and
future challenges of cloud computing's energy consumption. As demand for cloud
services continues to rise, there is a pressing need to explore alternative
technologies that can enhance energy efficiency without compromising on the
performance, availability and scalability of that the users expect.

One prevalent method for building cloud applications today involves using
serverless computing platforms, such as Amazon's *AWS Lambdas*, or Google's
*Cloud Functions*. These platforms let developers deploy code into containers
executed upon request. Despite the benefits, such as the ability to run software
across different architectures, this approach introduces a startup latency for
the containers. This latency is negligible for long-running services, but
significant for on-demand functions. 

This thesis proposes exploring WebAssembly and the WebAssembly System Interface
(WASI) as innovative choices for deploying functions to public cloud services.
WebAssembly, originally developed for efficient execution in web browsers,
combined with WASI, enables WebAssembly to run on servers, potentially offering
a more efficient way to package and deploy functions.

\section{Motivation}

The emergence of cloud computing has reshaped the landscape of digital services,
offering unparalleled scalability, flexibility, and efficiency. However, this
transformation comes with significant environmental implications. With the
increase in energy consumption in data centers, essential to cloud computing,
there needs to be a critical evaluation of the sustainability of the industry. 

Amidst growing concerns over the carbon footprint associated with cloud
services, there's a need for new and innovative solutions that can balance the
demands of the users and the impact on the planet. This thesis is motivated by
the opportunity to contribute to this balance by exploring the potential of
WebAssembly combined with the WebAssembly System Interface (WASI) for deploying
functions in the cloud more efficiently.

WebAssembly, originally designed for running demanding computations in web
browsers, present a promising technology that could help reduce the energy
consumption of cloud services. It offers an interesting option for packaging
functions with its compact binary format and fast execution time. This has the
potiential to significantly reduce startup latency and resource overhead
associated with traditional serverless platforms. This increased efficiency
could lead to a direct decrease in energy consumption for cloud services, which
in turn could motivate the industry to adopt alternative technology that enable
a more sustainable cloud.

\section{Methodology}

For this thesis, we will build a Functions-as-a-Service platform prototype,
named Nebula for brevity, that we deploy to a typical Debian web server. To
compare functions compiled and packaged into WebAssembly modules, we will write
standalone functions in Rust that we both A. compile to WebAssembly+WASI and B.
build as ordinary Rust binaries and package into a lightweight Docker image.
These WebAssembly modules and Docker images will be deployed to the web server,
ready to be called by our test scripts. 

On this server we will support running functions both as WebAssembly modules and
Docker Images, using a respective runtime for each. For WebAssembly Nebula will
use the Wasmtime project as runtime, while Docker relies on the Docker CLI tool. 
The act of calling these functions will be exposed as API endpoints, which allows 
a test script to call functions in succession in order to simulate user load.

Furthermore, a simple application will be written that hits this endpoint X
amount of times with Y amount of different input values. Nebula will benchmark
each individual function request based on the *Instant* crate in Rust, which in
turn will be stored in a JSON file with metric information. This list of
function results and metrics will lay the foundation for the findings the
experiments will reveal, which we will go into detail later.

*Hopefully*, there will also be time to set up Nebula to run on a Raspberry PI
that I can measure power consumption of during load of the web server, but this
is paragraph won't make it into the final paper, it's more of a TODO to me, to
not forget (how could I) to attempt to measure power consumption as well.

\section{Problem Statement}

1. Investigate potential optimization by employing an alternative way of
   deploying functions on a Functions-as-a-Service platform. 

2. Investigate potential energy savings from employing more efficient compute on
   cloud. 

\section{Outline}

This thesis has three parts: the introduction and background, the project, and
discussions about the findings and future work. Each part is divided into
chapters: 

- Chapter 1 - Introduction, where the project is introduced, the motivation
  lying behind it, the problem statement provided and the methodology used for
  the project work.
- Chapter 2 - Background, where the history of cloud computing has led to the
topic that is explored in this thesis. The concept of *three waves* of cloud
computing is introduced, and other vendors in the market are explored.
- Chapter 3 - 

\newpage

\chapter{Background}

\section{Cloud Computing: An Overview}

<!-- What is the cloud and its significance in web -->

Cloud computing, more commonly known as _the cloud_, refers to the delivery of
computing services, such as storage, processing power, network, and software,
served over the internet, instead of running on locally owned hardware
(on-premise). For companies, this has proved to be a super power, where
businesses can focus on deploying their own applications and services to their
users without worrying about the underlying infrastructure.

<!-- Some benefits and challenges -->

Some benefits include:

- Reduced total cost of ownership: Cloud computing has enabled companies to take
  their computing needs to the next level. Startups who can't afford neither the
  cost or time required to build their own infrastructure, and larger companies
  that want to iterate faster and decrease their lead time from idea to
  production [(Thomas, Dave. 2009)][6].

- Scalability is one of the most significant benefits of cloud computing. As
  organizations expand, so do their customer needs and the complexity of their
  application infrastructure. Each additional feature brings with it additional
  costs, highlighting the importance of efficient resource management to
  optimize hardware investments in a cloud computing environment
  [(Thomas, Dave. 2008)][6].

Some challenges include:

- Cost: Managing the cost of cloud computing is an ongoing challenge, with
  Gartner predicting that through 2024, 60% of infrastructure and operations
  (I&O) leaders will encounter cloud costs that are higher than budgeted for
  [(Rimol, M. 2021)][7].

- Energy usage: The challenge of energy usage in cloud computing is a
  significant concern, with data centers alone accounting for approximately 1%
  of the world's electricity consumption [(Freitag et al. 2021)][1]. This
  staggering statistic highlights the need to explore strategies and measures to
  mitigate energy usage in data centers. By reducing energy consumption, not
  only can costs be reduced, but also the carbon footprint associated with
  running the cloud can be lessened. Decreasing energy usage in data centers is
  expected to yield cost savings and contribute to the overall sustainability
  goals by reducing the cloud's environmental impact.

\subsection{Three waves of cloud compute}

\subsubsection{The first wave: Virtual machines}

<!-- Introduce the concept of "the first two waves of cloud computing" -->

In the era preceding cloud computing, companies bought, set up and managed their
own infrastructure. This necessitated having in-house infrastructure engineers
to maintain on-premise data centers or servers, leading to significant cost.
Sensing the potential in offering managed infrastructure, Amazon launched its
subsidiary, Amazon Web Services, during the mid-2000s.

The launch of AWS's Amazon S3 cloud service in March 2006, followed by Elastic
Compute Cloud (EC2) in August the same year [(Barr, J. 2006)][8], marked a major
turning point in application development and deployment, and popularized cloud
computing. EC2, as an Infrastructure-as-a-Service platform, empowered developers
to run virtual machines remotely. While similar services existed before 2006,
Amazon's large customer base helped them gain significant traction, effectively
bringing cloud computing to the mainstream.

\subsubsection{The second wave: Containerization}

As we entered the 2010s, the focus shifted from Virtual Machines to containers,
largely due to the limitations of VMs in efficiency, resource utilization, and
application deployment speed. Containers, being a lightweight alternative to
VMs, designed to overcome these hurdles [(Sharma, et al. 2016)][9].

In contrast to VMs, which require installation of resource-intensive operating
systems and minutes to start up, containers along with their required OS
components, could start up in seconds. Typically managed by orchestration tools
like [Kubernetes][10], containers enabled applications to package alongside
their required OS components, facilitating scalability in response to varying
service loads. Consequently, an increasing number of companies have since
established platform teams to build orchestrated developers platforms, thereby
simplifying application development in Kubernetes clusters.

\subsubsection{The third wave: WebAssembly}

\subsection{Serverless and Function-as-a-Service (FaaS)}

Building your own developer platform on top of Kubernetes, much like building
your own infrastructure, also entails a significant cost. Often, developers wish
to launch specialized smaller services, without having to grapple with
complicated orchestration. This led to the emergence of the Serverless model.
Despite its somewhat misleading name, serverless doesn't imply the absence of a
server. Instead, it means that the responsibility of server management has
shifted from the developer to a third party provider.

From the advancements of serverless, we get its subset, Functions-as-a-Service,
or FaaS. Companies already in the cloud game decided to develop their own FaaS
platforms to attract developers interested in just writing their functions and
running them, and not worry about anything underneath.

\subsubsection{Major vendors in Serverless}

The concept of "the cloud" isn't owned by any single organization, but rather,
through the collective effort of industry players including Amazon, Microsoft,
Google, Alibaba and DigitalOcean, among others. This essay delves into some
challenges faced by the biggest three vendors: Amazon, Google and Microsoft.

Amazon Web Services (AWS) provides [AWS Lambdas][11], a technology that hinges
on their proprietary Firecracker - a streamlined virtualization technology for
executing functions. Interestingly, for this thesis, is that Amazon's Prime
Video streaming service transitioned recently from a serverless architecture to
a monolithic system to meet specific service demands. One might question whether
this reflects the suitability of serverless systems for cloud computing, or for
specific use cases like theirs [(Kolny, M. 2023. Accessed 29.05.23)][12]. Some
discussions suggest that their need to process videos frame by frame led to
astronomical costs on their sibling company's FaaS, Amazon Lambda.

Google provides [Google Cloud Functions][13], which allow developers to write
and execute functions in languages such as Node.js, Python, Go and execute them
in response to events. Google's approach to function execution centeres around
container technology [(Wayner, P. 2018. Accessed 29.05.23)][14].

Microsoft's [Azure Functions][15] is a Faas platform that enables developers to
create and execute functions written in languages like C#, JavaScript, Python.
Similar to Google, they also harness the power of containers to execute these
functions.

<!-- Introduce FaaS as a concept and its role in "serverless" cloud computing  -->
<!-- Challenges associated with FaaS, including cold start latency -->

\subsection{WebAssembly}

<!-- Provide an overview of WebAssembly, its purpose, and its advantages over
traditional deployment methods. -->

WebAssembly (Wasm) is a binary instruction format designed as a stack-based
virtual machine. It aims to be a portable target for the compilation of
high-level languages like Rust, C++, Go and many others, enabling deployment on
the web for client and server applications. Originally designed and developed to
complement JavaScript in the browser, it now expands its scope to server-side
applications, thanks to projects like WebAssembly System Interface (WASI), which
provides a standarized interface for WebAssembly modules to interface with a
system.

WebAssembly's design provides advantages over traditional deployments methods in
the context of cloud native applications:

_Efficiency and Speed_: Wasm was designed to be fast, enabling near-native
performance. Its binary format is compact and designed for quick decoding,
contributing to quicker startup times, an important aspect for server-side
applications. The performance gains could lead to less CPU usage, thereby
improving energy efficiency.

_Safety and Security_: WebAssembly is designed to be safe and sandboxed. Each
WebAssembly module executes within a confined environment without direct access
to the host system's resources. This isolation of processes is inherent in
WebAssembly's design, promoting secure practices.

_Portability_: WebAssembly's platform-agnostic design makes it highly portable.
It can run across a variety of different system architectures. For cloud native
applications, this means WebAssembly modules, once compiled, can run anywhere -
from the edge to the server, irrespective of the environment.

_Language Support_: A large amount of programming langauages can already target
WebAssembly. This means developers are not restricted to a particular language
when developing applications intended to be deployed as WebAssembly modules.
This provides greater flexibility to leverage the most suitable languages for
particular tasks.

In contrast, traditional methods such as deployment with containers or VMs can
be resource-intensive, slower to boot up, less secure due to a larger surface
attack area, and less efficient. Given these, WebAssembly, with its efficiency,
security, and portability, can potentially offer an attractive alternative
deployment method for building and running cloud native applications, like the
"Academemes" service we will explore in this essay.

\subsubsection{WASM+WASI: Towards Energy-efficient FaaS Platforms}

WebAssembly (WASM) and [WebAssembly System Interface (WASI)][16] present
promising choices to traditional ways of deploying and hosting Function as
a Service (FaaS) platforms, offering several notable advantages, in
terms of startup times and energy efficiency.

_Reduced Startup Times_: One of the greatest strengths of Wasm is its compact
binary format designed for quick decoding and efficient execution. It offers
near-native performance, which results in significantly reduced startup times
compared to container-based or VM-based solutions. In a FaaS context, where
functions need to spin up rapidly in response to events, this attribute is
particularly advantageous. This not only contributes to the overall performance
but also improves the user experience, as the latency associated with function
initialization is minimized.

_Improved Energy Efficiency_: Wasm's efficiency extends to energy use as well.
Thanks to its optimized execution, Wasm can accomplish the same tasks as
traditional cloud applications but with less computational effort. The CPU
doesn't need to work as hard, which results in less energy consumed. With data
centers being responsible for a significant portion of global energy consumption
and carbon emissions, adopting Wasm could lead to substantial energy savings and
environmental benefits.

_Scalability_: Wasm's small footprint and fast startup times make it an
excellent fit for highly scalable cloud applications. Its efficiency means it
can handle many more requests within the same hardware resources, hence reducing
the need for additional servers and thus reducing the energy footprint further.

_Portability and Flexibility_: WASI extends the portability of Wasm outside the
browser environment, making it possible to run Wasm modules securely on any
WASI-compatible runtime. This means that FaaS platforms can run these modules on
any hardware, operating system, or cloud provider that supports WASI. This
portability ensures flexibility and mitigates the risk of vendor lock-in.

While runtime efficiency is an important aspect and typically a strength of
Wasm, it might not be the primary focus of this thesis. That being said, it is
worth mentioning that the efficient execution of Wasm modules does contribute to
the overall operational efficiency and energy savings of Wasm-based FaaS
platforms.

In summary, introducing WASM+WASI as a component for deploying and hosting FaaS
platforms can offer significant benefits. Focusing on energy efficiency and reduced startup times, this approach could pave the way for more sustainable,
efficient, and responsive cloud services. In the context of our "Academemes"
service, this could lead to a scalable, performant, and environmentally friendly
platform.

\newpage

\part{Project}
\chapter{Approach}

\newpage

\chapter{Design}

\newpage

\chapter{Implementation}

This is the chapter on implementing Nebula.

\section{Tech stack}

Rust/Docker/Etc.

\newpage

\part{Discussions and future works}

\subsection{Some Graphs}


\begin{table}
\centering
\begin{tabular}{ll}
Header 1 & Header 2 \\
\hline
Row 1 & Data \\
Row 2 & Data \\
\end{tabular}
\caption{Example Table}
\end{table}


\label{CustomLastPage}


\section{References}

[1]: https://dx.doi.org/10.1016/j.patter.2021.100340
[2]: https://doi.org/10.1038/s41558-020-0837-6
[3]: https://www.rust-lang.org/
[4]: https://webassembly.org/
[5]: https://ieeexplore.ieee.org/document/798396
[6]: https://dx.doi.org/10.5381/jot.2009.8.3.c4
[7]: https://www.gartner.com/smarterwithgartner/6-ways-cloud-migration-costs-go-off-the-rails
[8]: https://aws.amazon.com/blogs/aws/amazon_ec2_beta/
[9]: https://dx.doi.org/10.1145/2988336.2988337
[10]: https://kubernetes.io/
[11]: https://aws.amazon.com/lambda/
[12]: https://www.primevideotech.com/video-streaming/scaling-up-the-prime-video-audio-video-monitoring-service-and-reducing-costs-by-90
[13]: https://cloud.google.com/functions
[14]: https://www.infoworld.com/article/3265750/serverless-in-the-cloud-aws-vs-google-cloud-vs-microsoft-azure.html
[15]: https://learn.microsoft.com/en-us/azure/azure-functions/functions-overview
[16]: https://wasi.dev/
[17]: https://www.fermyon.com/spin
[18]: https://luiscruz.github.io/2021/07/20/measuring-energy.html
[19]: https://www.intel.com/content/www/us/en/developer/articles/technical/software-security-guidance/advisory-guidance/running-average-power-limit-energy-reporting.html
[20]: http://dx.doi.org/10.1145/3177754

